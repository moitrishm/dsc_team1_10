{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_heart_data():\n",
    "    return pd.read_csv(Path(\"datasets/ptbdb_normal.csv\"))\n",
    "\n",
    "\n",
    "def load_abnormal_data():\n",
    "    return pd.read_csv(Path(\"datasets/ptbdb_abnormal.csv\"))\n",
    "\n",
    "\n",
    "healthy_heart_data = load_heart_data()\n",
    "unhealthy_heart_data = load_abnormal_data()\n",
    "healthy_heart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [healthy_heart_data, unhealthy_heart_data]\n",
    "\n",
    "for df in dfs:\n",
    "    df.columns = list(range(len(df.columns)))\n",
    "\n",
    "data = pd.concat(dfs, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
    "data.rename(columns={data.columns[-1]: \"Target\"}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Target\", axis=1)\n",
    "y = data[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(tree_method=\"hist\")\n",
    "\n",
    "clf.fit(X_train, y_train, eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"learning_rate\": [0.2],\n",
    "    \"max_depth\": [7],\n",
    "    \"subsample\": [0.8, 0.7],\n",
    "    \"colsample_bytree\": [1.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=clf, param_grid=param_grid, scoring=\"accuracy\", cv=3, verbose=2, n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# Initialize the classifier with the best hyperparameters\n",
    "best_clf = xgb.XGBClassifier(\n",
    "    colsample_bytree=best_params[\"colsample_bytree\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    subsample=best_params[\"subsample\"],\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Retrain the classifier on the entire training data\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(\"Cross-Validation Accuracy Scores:\", scores)\n",
    "print(\"Mean Cross-Validation Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(clf, 'xgboost_model.pkl')\n",
    "\n",
    "# Load the model\n",
    "clf = joblib.load('xgboost_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_true_data():\n",
    "    return pd.read_csv(Path(\"datasets/mitbih_train.csv\"))\n",
    "\n",
    "data2 = load_true_data()\n",
    "data2.columns = list(range(len(data2.columns)))\n",
    "\n",
    "data2.rename(columns={data2.columns[-1]: \"Target\"}, inplace=True)\n",
    "data2['Target'] = data2['Target'].apply(lambda x: 1 if x != 0 else 0)\n",
    "data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = data2.iloc[:,:-1]\n",
    "y2 = data2['Target']\n",
    "\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
    "\n",
    "# Evaluate the model on the new dataset\n",
    "best_clf.fit(X_train_new, y_train_new)\n",
    "y_pred_new = best_clf.predict(X_test_new)\n",
    "print(\"Evaluation on New Dataset:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_new, y_pred_new)}\")\n",
    "print(f\"Precision: {precision_score(y_test_new, y_pred_new, average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_test_new, y_pred_new, average='weighted')}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_new, y_pred_new, average='weighted')}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_new, y_pred_new)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test_new, y_pred_new)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100],\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"max_depth\": [5],\n",
    "    \"subsample\": [0.9],\n",
    "    \"colsample_bytree\": [1.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=clf, param_grid=param_grid, scoring=\"accuracy\", cv=3, verbose=2, n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train_new, y_train_new)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# Initialize the classifier with the best hyperparameters\n",
    "best2_clf = xgb.XGBClassifier(\n",
    "    colsample_bytree=best_params[\"colsample_bytree\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    subsample=best_params[\"subsample\"],\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Retrain the classifier on the entire training data\n",
    "best2_clf.fit(X_train_new, y_train_new)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_new = best2_clf.predict(X_test_new)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_new, y_pred_new)\n",
    "precision = precision_score(y_test_new, y_pred_new, average=\"weighted\")\n",
    "recall = recall_score(y_test_new, y_pred_new, average=\"weighted\")\n",
    "f1 = f1_score(y_test_new, y_pred_new, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test_new, y_pred_new)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test_new, y_pred_new)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = data.iloc[:,:-1]\n",
    "y2 = data['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "y_pred_new = best2_clf.predict(X_test)\n",
    "print(\"Evaluation on New Dataset:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_new)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_new, average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_new, average='weighted')}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_new, average='weighted')}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_new)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_new)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
